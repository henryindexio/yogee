{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load features and target dataframe\n",
    "import pickle\n",
    "\n",
    "f = open('/home/henry/Insight/Yogee/Datasets/Model_dataset/ModelDf.pckl', 'rb')\n",
    "ModelDf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 2017 data\n",
    "ModelDf = ModelDf[ModelDf['year'] != 2017]\n",
    "ModelDf = ModelDf.reset_index(drop=True)\n",
    "\n",
    "#Reduced land area size\n",
    "ModelDf.loc[:,'LandArea'] = ModelDf.loc[:,'LandArea']/100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get zipcodes in the dataset\n",
    "\n",
    "#Load population dataset\n",
    "Population2011FileLoc = \"/home/henry/Insight/Yogee/Datasets/NY_Population_dataset/ACS_11_5YR_B01003/ACS_11_5YR_B01003_with_ann.csv\"\n",
    "Population2011Df = pd.read_csv(Population2011FileLoc)\n",
    "\n",
    "#Get zipcodes to use\n",
    "zipcodes = Population2011Df.loc[:,'GEO.id2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove zipcodes with less than 100 people\n",
    "for i in range(0,zipcodes.shape[0]):\n",
    "    if Population2011Df.loc[i,'HD01_VD01'] < 100:\n",
    "        zipcode = zipcodes[i]\n",
    "        ModelDf = ModelDf[ModelDf['zip'] != zipcode]\n",
    "        zipcodes = zipcodes.drop(i)\n",
    "zipcodes = zipcodes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test set by selecting 2016 data\n",
    "TestData = ModelDf[ModelDf['year'] == 2016]\n",
    "TestData = TestData.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create valiation set by selecting 2015 data\n",
    "ValidData = ModelDf[ModelDf['year'] == 2015]\n",
    "ValidData = ValidData.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train set by removing 2015 and 2016 data\n",
    "TrainData = ModelDf[(ModelDf['year'] != 2016) & (ModelDf['year'] != 2015)]\n",
    "TrainData = TrainData.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate predictor and target variables\n",
    "TestDataX = TestData.loc[:,['population','FemaleRatio','Income','LandArea','PopDensity','TotalStudio']]\n",
    "TestDataY = TestData.loc[:,['NewStudioNextYearBin']]\n",
    "ValidDataX = ValidData.loc[:,['population','FemaleRatio','Income','LandArea','PopDensity','TotalStudio']]\n",
    "ValidDataY = ValidData.loc[:,['NewStudioNextYearBin']]\n",
    "TrainDataX = TrainData.loc[:,['population','FemaleRatio','Income','LandArea','PopDensity','TotalStudio']]\n",
    "TrainDataY = TrainData.loc[:,['NewStudioNextYearBin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocessing of train, validation, and test datasets\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Fill in missing data and scale input data\n",
    "imputer = preprocessing.Imputer()\n",
    "TestDataTransX = imputer.fit_transform(TestDataX)/10000\n",
    "TestDataScaledX = preprocessing.scale(TestDataTransX).tolist()\n",
    "ValidDataTransX = imputer.fit_transform(ValidDataX)/10000\n",
    "ValidDataScaledX = preprocessing.scale(ValidDataTransX).tolist()\n",
    "TrainDataTransX = imputer.fit_transform(TrainDataX)/10000\n",
    "TrainDataScaledX = preprocessing.scale(TrainDataTransX).tolist()\n",
    "\n",
    "TestDataValuesY = TestDataY.values.ravel().tolist()\n",
    "ValidDataValuesY = ValidDataY.values.ravel().tolist()\n",
    "TrainDataValuesY = TrainDataY.values.ravel().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26673419, -0.06463971,  0.63086794, -0.16778327, -0.14900186,\n",
       "         0.15834651]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and valid dataset for logistic regression\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "#make model pipeline to upsample with SMOTE and train logistic regression model\n",
    "LR = linear_model.LogisticRegression()\n",
    "pipeline = make_pipeline(SMOTE(random_state=RANDOM_STATE),\n",
    "                         LR)\n",
    "pipeline.fit(TrainDataScaledX,TrainDataValuesY)\n",
    "LogValidY = pipeline.predict(ValidDataScaledX)\n",
    "LogValidProbaY = pipeline.predict_proba(ValidDataScaledX) \n",
    "LogLoss = metrics.log_loss(ValidDataValuesY,LogValidY)\n",
    "LogAcc = metrics.accuracy_score(np.round(ValidDataValuesY),np.round(LogValidY))\n",
    "LogWeights = LR.coef_\n",
    "LogConfusionMatrix = metrics.confusion_matrix(ValidDataValuesY, LogValidY)\n",
    "\n",
    "LogTestY = pipeline.predict(TestDataScaledX)\n",
    "LogTestProbaY = pipeline.predict_proba(TestDataScaledX) \n",
    "LogLoss = metrics.log_loss(TestDataValuesY,LogTestY)\n",
    "LogAcc = metrics.accuracy_score(np.round(TestDataValuesY),np.round(LogTestY))\n",
    "LogWeights = LR.coef_\n",
    "LogConfusionMatrix = metrics.confusion_matrix(TestDataValuesY, LogTestY)\n",
    "LogTruePos = LogConfusionMatrix[1,1]/(LogConfusionMatrix[1,1] + LogConfusionMatrix[1,0])\n",
    "LogFalsePos = LogConfusionMatrix[0,1]/(LogConfusionMatrix[0,1] + LogConfusionMatrix[0,0])\n",
    "LogROCUpperLeft = LogTruePos + (1-LogFalsePos)\n",
    "LogWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6019061583577712"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and valid dataset for support vector machine\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "#make model pipeline to upsample with SMOTE and train logistic regression model\n",
    "SVM = svm.SVC(C = .01, kernel = 'linear', probability = True)\n",
    "pipeline = make_pipeline(SMOTE(random_state=RANDOM_STATE), SVM)\n",
    "\n",
    "pipeline.fit(TrainDataScaledX,TrainDataValuesY)\n",
    "SVMValidY = pipeline.predict(ValidDataScaledX)\n",
    "SVMValidProbaY = pipeline.predict_proba(ValidDataScaledX) \n",
    "SVMLoss = metrics.log_loss(ValidDataValuesY,SVMValidY)\n",
    "SVMAcc = metrics.accuracy_score(np.round(ValidDataValuesY),np.round(SVMValidY))\n",
    "SVMWeights = SVM.coef_\n",
    "SVMConfusionMatrix = metrics.confusion_matrix(ValidDataValuesY, SVMValidY)\n",
    "SVMTruePos = SVMConfusionMatrix[1,1]/(SVMConfusionMatrix[1,1] + SVMConfusionMatrix[1,0])\n",
    "SVMFalsePos = SVMConfusionMatrix[0,1]/(SVMConfusionMatrix[0,1] + SVMConfusionMatrix[0,0])\n",
    "SVMROCUpperLeft = SVMTruePos + (1-SVMFalsePos)\n",
    "SVMROCUpperLeft\n",
    "\n",
    "SVMTestY = pipeline.predict(TestDataScaledX)   \n",
    "SVMTestProbaY = pipeline.predict_proba(TestDataScaledX) \n",
    "SVMLoss = metrics.log_loss(TestDataValuesY,SVMTestY)\n",
    "SVMAcc = metrics.accuracy_score(np.round(TestDataValuesY),np.round(SVMTestY))\n",
    "SVMWeights = SVM.coef_\n",
    "SVMConfusionMatrix = metrics.confusion_matrix(TestDataValuesY, SVMTestY)\n",
    "SVMTruePos = SVMConfusionMatrix[1,1]/(SVMConfusionMatrix[1,1] + SVMConfusionMatrix[1,0])\n",
    "SVMFalsePos = SVMConfusionMatrix[0,1]/(SVMConfusionMatrix[0,1] + SVMConfusionMatrix[0,0])\n",
    "SVMROCUpperLeft = SVMTruePos + (1-SVMFalsePos)\n",
    "SVMROCUpperLeft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/anaconda3/envs/insight/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.588111591294953"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and valid dataset for random forest\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "RF = ensemble.RandomForestClassifier(n_estimators=3 , max_depth=3)\n",
    "#make model pipeline to upsample with SMOTE and random forest model\n",
    "pipeline = make_pipeline(SMOTE(random_state=RANDOM_STATE), RF)\n",
    "pipeline.fit(TrainDataScaledX,TrainDataValuesY)\n",
    "RFValidY = pipeline.predict(ValidDataScaledX)  \n",
    "RFValidProbaY = pipeline.predict_proba(ValidDataScaledX)    \n",
    "RFLoss = metrics.log_loss(ValidDataValuesY,RFValidY)\n",
    "RFAcc = metrics.accuracy_score(np.round(ValidDataValuesY),np.round(RFValidY))\n",
    "RDFeatureImportances = RF.feature_importances_\n",
    "RFConfusionMatrix = metrics.confusion_matrix(ValidDataValuesY, RFValidY)\n",
    "RFTruePos = RFConfusionMatrix[1,1]/(RFConfusionMatrix[1,1] + RFConfusionMatrix[1,0])\n",
    "RFFalsePos = RFConfusionMatrix[0,1]/(RFConfusionMatrix[0,1] + RFConfusionMatrix[0,0])\n",
    "RFROCUpperLeft = RFTruePos + (1-RFFalsePos)\n",
    "\n",
    "RFTestY = pipeline.predict(TestDataScaledX) \n",
    "RFTestProbaY = pipeline.predict_proba(TestDataScaledX)    \n",
    "RFLoss = metrics.log_loss(TestDataValuesY,RFTestY)\n",
    "RFAcc = metrics.accuracy_score(np.round(TestDataValuesY),np.round(RFTestY))\n",
    "RDFeatureImportances = RF.feature_importances_\n",
    "RFConfusionMatrix = metrics.confusion_matrix(TestDataValuesY, RFTestY)\n",
    "RFTruePos = RFConfusionMatrix[1,1]/(RFConfusionMatrix[1,1] + RFConfusionMatrix[1,0])\n",
    "RFFalsePos = RFConfusionMatrix[0,1]/(RFConfusionMatrix[0,1] + RFConfusionMatrix[0,0])\n",
    "RFROCUpperLeft = RFTruePos + (1-RFFalsePos)\n",
    "RFROCUpperLeft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.508045223028245"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and valid dataset for gradient boosting\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "GB =  ensemble.GradientBoostingClassifier(n_estimators=5 , max_depth=4, learning_rate = 0.01)\n",
    "#make model pipeline to upsample with SMOTE and gradient boosting model\n",
    "pipeline = make_pipeline(SMOTE(random_state=RANDOM_STATE), GB)\n",
    "pipeline.fit(TrainDataScaledX,TrainDataValuesY)\n",
    "GBValidY = pipeline.predict(ValidDataScaledX)\n",
    "GBValidProbaY = pipeline.predict_proba(ValidDataScaledX)    \n",
    "GBLoss = metrics.log_loss(ValidDataValuesY,GBValidY)\n",
    "GBAcc = metrics.accuracy_score(np.round(ValidDataValuesY),np.round(GBValidY))\n",
    "GBFeatureImportances = GB.feature_importances_\n",
    "GBConfusionMatrix = metrics.confusion_matrix(ValidDataValuesY, GBValidY)\n",
    "GBTruePos = GBConfusionMatrix[1,1]/(GBConfusionMatrix[1,1] + GBConfusionMatrix[1,0])\n",
    "GBFalsePos = GBConfusionMatrix[0,1]/(GBConfusionMatrix[0,1] + GBConfusionMatrix[0,0])\n",
    "GBROCUpperLeft = GBTruePos + (1-GBFalsePos)\n",
    "GBROCUpperLeft\n",
    "\n",
    "GBTestY = pipeline.predict(TestDataScaledX) \n",
    "GBTestProbaY = pipeline.predict_proba(TestDataScaledX)    \n",
    "GBLoss = metrics.log_loss(TestDataValuesY,GBTestY)\n",
    "GBAcc = metrics.accuracy_score(np.round(TestDataValuesY),np.round(GBTestY))\n",
    "GBFeatureImportances = GB.feature_importances_\n",
    "GBConfusionMatrix = metrics.confusion_matrix(TestDataValuesY, GBTestY)\n",
    "GBTruePos = GBConfusionMatrix[1,1]/(GBConfusionMatrix[1,1] + GBConfusionMatrix[1,0])\n",
    "GBFalsePos = GBConfusionMatrix[0,1]/(GBConfusionMatrix[0,1] + GBConfusionMatrix[0,0])\n",
    "GBROCUpperLeft = GBTruePos + (1-GBFalsePos)\n",
    "GBROCUpperLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot ROC curves the models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logreg_roc_auc = roc_auc_score(TestDataValuesY, LogTestY)\n",
    "fpr1, tpr1, thresholds1 = roc_curve(TestDataValuesY, LogTestProbaY[:,1])\n",
    "\n",
    "support_roc_auc = roc_auc_score(TestDataValuesY, SVMTestY)\n",
    "fpr2, tpr2, thresholds2 = roc_curve(TestDataValuesY, SVMTestProbaY[:,1])\n",
    "\n",
    "forest_roc_auc = roc_auc_score(TestDataValuesY, RFTestY)\n",
    "fpr3, tpr3, thresholds3 = roc_curve(TestDataValuesY, RFTestProbaY[:,1])\n",
    "\n",
    "gradientboot_roc_auc = roc_auc_score(TestDataValuesY, GBTestY)\n",
    "fpr4, tpr4, thresholds4 = roc_curve(TestDataValuesY, GBTestProbaY[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr1, tpr1, label='Logistic Regression (area = %0.2f)' % logreg_roc_auc)\n",
    "plt.plot(fpr2, tpr2, label='Support Vector Machine (area = %0.2f)' % support_roc_auc)\n",
    "plt.plot(fpr3, tpr3, label='Random Forest (area = %0.2f)' % forest_roc_auc)\n",
    "plt.plot(fpr4, tpr4, label='Gradient Boosting (area = %0.2f)' % gradientboot_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542.2746748447178"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train logistic regression model with full dataset to get predictive model\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "#Get train predict dataset and separate into X and Y\n",
    "TrainData = ModelDf[(ModelDf['year'] != 2016)]\n",
    "TrainData = TrainData.reset_index(drop=True)\n",
    "TrainDataX = TrainData.loc[:,['population','FemaleRatio','Income','LandArea','PopDensity','TotalStudio']]\n",
    "TrainDataY = TrainData.loc[:,['NewStudioNextYearBin']]\n",
    "\n",
    "PredictData = ModelDf[ModelDf['year'] == 2016]\n",
    "PredictData = PredictData.reset_index(drop=True)\n",
    "PredictDataX = PredictData.loc[:,['population','FemaleRatio','Income','LandArea','PopDensity','TotalStudio']]\n",
    "PredictDataY = PredictData.loc[:,['NewStudioNextYearBin']]\n",
    "\n",
    "#Fill in missing data and scale input data\n",
    "imputer = preprocessing.Imputer()\n",
    "TrainDataTransX = imputer.fit_transform(TrainDataX)/10000\n",
    "TrainDataScaledX = preprocessing.scale(TrainDataTransX).tolist()\n",
    "PredictDataTransX = imputer.fit_transform(PredictDataX)/10000\n",
    "PredictDataScaledX = preprocessing.scale(PredictDataTransX).tolist()\n",
    "\n",
    "TrainDataValuesY = TrainDataY.values.ravel().tolist()\n",
    "PredictDataValuesY = PredictDataY.values.ravel().tolist()\n",
    "\n",
    "#Train model for logistic regression\n",
    "#make model pipeline to upsample with SMOTE and train logistic regression model\n",
    "LR = linear_model.LogisticRegression()\n",
    "pipeline = make_pipeline(SMOTE(random_state=RANDOM_STATE),\n",
    "                         LR)\n",
    "pipeline.fit(TrainDataScaledX,TrainDataValuesY)\n",
    "LogPredictY = pipeline.predict(PredictDataScaledX)\n",
    "LogPredictProbaY = pipeline.predict_proba(PredictDataScaledX) \n",
    "LogLoss = metrics.log_loss(PredictDataValuesY,LogPredictY)\n",
    "LogAcc = metrics.accuracy_score(np.round(PredictDataValuesY),np.round(LogPredictY))\n",
    "LogWeights = LR.coef_\n",
    "LogConfusionMatrix = metrics.confusion_matrix(PredictDataValuesY, LogPredictY)\n",
    "LogTruePos = LogConfusionMatrix[1,1]/(LogConfusionMatrix[1,1] + LogConfusionMatrix[1,0])\n",
    "LogFalsePos = LogConfusionMatrix[0,1]/(LogConfusionMatrix[0,1] + LogConfusionMatrix[0,0])\n",
    "LogROCUpperLeft = LogTruePos + (1-LogFalsePos)\n",
    "\n",
    "#Put model predictions in dataframe\n",
    "np.sum(LogPredictProbaY[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7419354838709677"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogConfusionMatrix\n",
    "23/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogPredictProbaY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fc1ac0f3b8c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPredictDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'zip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mProbaDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogPredictProbaY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NewStoreProbability'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mScoreDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogPredictProbaY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mPredictDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPredictDF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProbaDf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScoreDf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogPredictProbaY' is not defined"
     ]
    }
   ],
   "source": [
    "PredictDF = PredictData['zip']\n",
    "ProbaDf = pd.DataFrame(LogPredictProbaY[:,1],columns=['NewStoreProbability'])\n",
    "ScoreDf = pd.DataFrame(LogPredictProbaY[:,1]*10,columns=['Score'])\n",
    "PredictDF = pd.concat([PredictDF, ProbaDf, ScoreDf], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('/home/henry/Insight/Yogee/Model/PredictModel.pckl', 'wb')\n",
    "pickle.dump(pipeline, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('/home/henry/Insight/Yogee/Model/PredictDF.pckl', 'wb')\n",
    "pickle.dump(PredictDF, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('/home/henry/Insight/Yogee/Model/PredictDF.pckl', 'rb')\n",
    "PredictDF = pickle.load(f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
